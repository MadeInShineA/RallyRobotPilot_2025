{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0c70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import lzma\n",
    "import pickle\n",
    "import polars as pl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a59b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polars.config.Config"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.Config.set_tbl_rows(-1)\n",
    "pl.Config.set_tbl_cols(-1)\n",
    "pl.Config.set_tbl_width_chars(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30840d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarPilotNet(nn.Module):\n",
    "    def __init__(self, n_inputs=16, n_outputs=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, n_outputs)  # raw logits for [fwd, back, left, right]\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde07423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(record_dir = \"./records/\"):\n",
    "    all_records = []  # Accumulate all records here\n",
    "\n",
    "    for filename in os.listdir(record_dir):\n",
    "        if not filename.endswith(\".npz\"):\n",
    "            continue\n",
    "\n",
    "        input_path = os.path.join(record_dir, filename)\n",
    "        try:\n",
    "            with lzma.open(input_path, \"rb\") as _f:\n",
    "                snapshots = pickle.load(_f)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        for _idx, s in enumerate(snapshots):\n",
    "            record = {\n",
    "                \"record\": filename,\n",
    "                \"frame_idx\": _idx,\n",
    "                \"forward\": s.current_controls[0],\n",
    "                \"back\": s.current_controls[1],\n",
    "                \"left\": s.current_controls[2],\n",
    "                \"right\": s.current_controls[3],\n",
    "                \"car_speed\": s.car_speed,\n",
    "                **{f\"raycast_{i}\": float(d) for i, d in enumerate(s.raycast_distances)},\n",
    "            }\n",
    "            all_records.append(record)\n",
    "\n",
    "    # Create a single Polars DataFrame from all records\n",
    "    try:\n",
    "        df = pl.DataFrame(all_records).sort(\"record\")\n",
    "        print(f\"✅ Successfully created combined Polars DataFrame with {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error creating combined DataFrame: {e}\")\n",
    "    return df.filter((pl.col(\"raycast_7\") >= 50) & (pl.col(\"forward\") == 0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919d1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully created combined Polars DataFrame with 23058 rows\n",
      "Epoch 010 | Loss: 0.2462\n",
      "Epoch 020 | Loss: 0.2175\n",
      "Epoch 030 | Loss: 0.2034\n",
      "Epoch 040 | Loss: 0.2170\n",
      "Epoch 050 | Loss: 0.1955\n",
      "Epoch 060 | Loss: 0.1750\n",
      "Epoch 070 | Loss: 0.1694\n",
      "Epoch 080 | Loss: 0.1760\n",
      "Epoch 090 | Loss: 0.1644\n",
      "Epoch 100 | Loss: 0.1899\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# Load or simulate your dataset\n",
    "# ---------------------------------\n",
    "n_rays = 15\n",
    "n_samples = 5000\n",
    "\n",
    "# Instantiate\n",
    "model = CarPilotNet(n_inputs=n_rays+1, n_outputs=4)\n",
    "\n",
    "# Extract data\n",
    "\n",
    "df = extract_data()\n",
    "X = df.select(pl.exclude(['forward', 'back', 'left', 'right', 'record', 'frame_idx']))\n",
    "\n",
    "# build expressions to replace car_speed and raycast_* columns\n",
    "raycast_exprs = [pl.col(f\"raycast_{i}\") / 100 for i in range(n_rays)]\n",
    "car_speed_expr = (pl.col(\"car_speed\") + 50) / 100\n",
    "\n",
    "# apply the transformations (expressions replace the existing columns)\n",
    "X = X.with_columns([car_speed_expr] + raycast_exprs).to_numpy()\n",
    "    \n",
    "Y = df.select(pl.col(['forward','back','left','right'])).to_numpy()\n",
    "#[fwd, back, left, right]\n",
    "\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# ---------------------------------\n",
    "# Initialize model, loss, optimizer\n",
    "# ---------------------------------\n",
    "model = CarPilotNet(n_inputs=X.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ---------------------------------\n",
    "# Training loop\n",
    "# ---------------------------------\n",
    "epochs = 100\n",
    "# assume: logits shape (B,4), yb shape (B,4), xb shape (B, n_inputs)\n",
    "# xb column order: [car_speed_normalized, raycast_0..raycast_14]\n",
    "# car_speed_original = xb[:,0]*100 - 50  # if you stored normalized speed as (speed+50)/100\n",
    "# hyperparameters\n",
    "penalty_weight_pos = 1.2   # your existing positive penalty (encourage forward when slow)\n",
    "penalty_weight_neg = 1.0   # new negative penalty (discourage forward when too fast)\n",
    "speed_low = -5.0\n",
    "speed_high = 5.0\n",
    "\n",
    "bce_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in loader:\n",
    "        logits = model(xb)\n",
    "        base_loss = criterion(logits, yb)\n",
    "\n",
    "        # recover original speed from normalized column 0 (if you used (speed+50)/100)\n",
    "        speed_orig = xb[:, 0] * 100.0 - 50.0\n",
    "\n",
    "        # POSITIVE penalty: encourage forward=1 when speed in [speed_low, speed_high] and GT forward == 0\n",
    "        mask_pos = (speed_orig >= speed_low) & (speed_orig <= speed_high) & (yb[:, 0] == 0)\n",
    "\n",
    "        extra_loss = 0.0\n",
    "\n",
    "        if mask_pos.any():\n",
    "            logits_fwd_pos = logits[mask_pos, 0].unsqueeze(1)    # shape (M,1)\n",
    "            target_ones = torch.ones_like(logits_fwd_pos)\n",
    "            extra_loss_pos = bce_fn(logits_fwd_pos, target_ones)\n",
    "            extra_loss = extra_loss + penalty_weight_pos * extra_loss_pos\n",
    "\n",
    "        # NEGATIVE penalty: discourage forward=1 when speed is too high and GT forward == 1\n",
    "        mask_neg = (speed_orig > speed_high) & (yb[:, 0] == 1)\n",
    "\n",
    "        if mask_neg.any():\n",
    "            logits_fwd_neg = logits[mask_neg, 0].unsqueeze(1)    # shape (N,1)\n",
    "            target_zeros = torch.zeros_like(logits_fwd_neg)\n",
    "            extra_loss_neg = bce_fn(logits_fwd_neg, target_zeros)\n",
    "            extra_loss = extra_loss + penalty_weight_neg * extra_loss_neg\n",
    "\n",
    "        # final loss\n",
    "        if isinstance(extra_loss, float) and extra_loss == 0.0:\n",
    "            loss = base_loss\n",
    "        else:\n",
    "            loss = base_loss + extra_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d} | Loss: {total_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "119c4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ed37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌───────────┐\n",
      "│ car_speed │\n",
      "│ ---       │\n",
      "│ f64       │\n",
      "╞═══════════╡\n",
      "│ 49.879276 │\n",
      "└───────────┘\n",
      "shape: (1, 1)\n",
      "┌───────────┐\n",
      "│ car_speed │\n",
      "│ ---       │\n",
      "│ f64       │\n",
      "╞═══════════╡\n",
      "│ 0.0       │\n",
      "└───────────┘\n"
     ]
    }
   ],
   "source": [
    "rays = df.select([f\"raycast_{i}\" for i in range(n_rays)])\n",
    "speed = df.select('car_speed')\n",
    "print(speed.max())\n",
    "print(speed.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a649eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import lzma\n",
    "import pickle\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from typing import Optional, Union\n",
    "\n",
    "def sample_rays(rng: np.random.Generator):\n",
    "    center = rng.integers(0, 3)\n",
    "    base = [100.0]*15\n",
    "    if center == 0:\n",
    "        for i in range(15):\n",
    "            base[i] = max(20.0, min(100.0, rng.normal(85, 8)))\n",
    "    elif center == 1:\n",
    "        for i in range(15):\n",
    "            base[i] = max(5.0, min(100.0, rng.normal(60, 20)))\n",
    "    else:\n",
    "        for i in range(15):\n",
    "            angle = abs(i-7)/7.0\n",
    "            base[i] = max(1.0, min(100.0, rng.normal(20 + 80*angle, 12)))\n",
    "    for _ in range(rng.integers(0, 3)):\n",
    "        idx = rng.integers(0, 15)\n",
    "        drop = rng.uniform(5,60)\n",
    "        base[idx] = max(0.5, base[idx] - drop)\n",
    "    return [float(round(x,3)) for x in base]\n",
    "\n",
    "def label_from_state(rays, speed,\n",
    "                     rng: Optional[np.random.Generator] = None,\n",
    "                     flip_prob: float = 0.02,\n",
    "                     front_threshold: float = 5.0,\n",
    "                     side_diff_threshold: float = 6.0):\n",
    "    \"\"\"\n",
    "    Deterministic when `rng` is a numpy Generator created with a fixed seed.\n",
    "    Parameters:\n",
    "    - rays: sequence of distance readings (length >= 15 assumed)\n",
    "    - speed: scalar speed\n",
    "    - rng: optional np.random.Generator for deterministic randomness. If None, function is deterministic with no flips.\n",
    "    - flip_prob: probability to randomly flip each control bit (applied independently)\n",
    "    - front_threshold: distance threshold to trigger 'back' (=1)\n",
    "    - side_diff_threshold: difference between left/right means to steer\n",
    "    Returns: [f, b, l, r] as ints\n",
    "    \"\"\"\n",
    "    # base deterministic decisions\n",
    "    f = b = l = r = 0\n",
    "    front = min(rays[6:9])\n",
    "    left_mean = sum(rays[0:5]) / 5.0\n",
    "    right_mean = sum(rays[10:15]) / 5.0\n",
    "\n",
    "    if front < front_threshold:\n",
    "        b = 1\n",
    "    else:\n",
    "        if speed < 5:\n",
    "            f = 1\n",
    "    if speed > 10:\n",
    "        f = 0\n",
    "\n",
    "    if left_mean < right_mean - side_diff_threshold:\n",
    "        r = 1\n",
    "    elif right_mean < left_mean - side_diff_threshold:\n",
    "        l = 1\n",
    "\n",
    "    # apply small random flips only if rng provided\n",
    "    if rng is not None and flip_prob > 0.0:\n",
    "        if rng.random() < flip_prob:\n",
    "            l = 1 - l\n",
    "        if rng.random() < flip_prob:\n",
    "            r = 1 - r\n",
    "        if rng.random() < flip_prob:\n",
    "            f = 1 - f\n",
    "        if rng.random() < flip_prob:\n",
    "            b = 1 - b\n",
    "\n",
    "    return [int(f), int(b), int(l), int(r)]\n",
    "\n",
    "def make_synthetic_snapshots(n_snapshots, seed: Optional[Union[int, np.integer]] = None, flip_prob: float = 0.02):\n",
    "    \"\"\"\n",
    "    Creates snapshots reproducibly when `seed` is provided.\n",
    "    - seed: integer or None. If integer, uses np.random.default_rng(seed) for all sampling.\n",
    "    - flip_prob: forwarded to label_from_state for controlled randomness.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)  # modern, isolated RNG best practice.\n",
    "    snapshots = []\n",
    "    for _ in range(n_snapshots):\n",
    "        rays = sample_rays(rng)\n",
    "        speed = float(round(rng.uniform(-10, 50), 3))\n",
    "        controls = label_from_state(rays, speed, rng=rng, flip_prob=flip_prob)\n",
    "        s = SimpleNamespace(\n",
    "            current_controls=controls,\n",
    "            car_speed=speed,\n",
    "            raycast_distances=list(rays)\n",
    "        )\n",
    "        snapshots.append(s)\n",
    "    return snapshots\n",
    "\n",
    "def save_snapshots_lzma_pickle(snapshots, out_path):\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with lzma.open(out_path, \"wb\") as f:\n",
    "        pickle.dump(snapshots, f)\n",
    "\n",
    "    # writes the same format your extract_data expects\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with lzma.open(out_path, \"wb\") as f:\n",
    "        pickle.dump(snapshots, f)\n",
    "\n",
    "# Example usage: create 1 synthetic record file with 100 frames\n",
    "snapshots = make_synthetic_snapshots(20000, seed=42)\n",
    "save_snapshots_lzma_pickle(snapshots, \"./records/synth_record_0001.npz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e49d84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rallyrobotpilot-2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
